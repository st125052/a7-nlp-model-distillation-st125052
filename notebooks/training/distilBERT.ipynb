{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "In this lecture, we will explore the architecture of DistilBERT, its key components, and how it can be utilized for various natural language processing tasks. Additionally, we'll discuss its advantages, limitations, and provide hands-on examples to showcase its effectiveness.\n",
    "\n",
    "Reference : [The Theory](https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a) | [Code](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.16.1', '4.36.2', '1.13.1+cu117')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datasets --upgrade\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "datasets.__version__, transformers.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading our MNLI part of the GLUE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "###1. Load Dataset\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "task_name = \"mnli\"\n",
    "raw_datasets = datasets.load_dataset(\"glue\", task_name)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': 0, 'neutral': 1, 'contradiction': 2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = raw_datasets['train'].features['label'].names\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'entailment', 1: 'neutral', 2: 'contradiction'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: v for v, i in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "num_labels = np.unique(raw_datasets['train']['label']).size\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/BERT_embed.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "teacher_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id, \n",
    "    num_labels = num_labels,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")\n",
    "\n",
    "teacher_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, max_length=128, truncation=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff80d9a7107d4920ae4e69a782bf42cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea41c6eb4ae4d92996c0fcebac3adce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a104a2ae77643d7ba0010ecc94ec336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef3b49ea0cb4a7196e97e67fadcf2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d8f5348fff434e9de681abcf132dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['premise', 'hypothesis']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(task_to_keys[task_name])\n",
    "column_dataset = [item for item in task_to_keys[task_name] if item is not None]\n",
    "column_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove column : 'premise', 'hypothesis', 'idx'\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(column_dataset + [\"idx\"])\n",
    "#rename column : 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#Data collator that will dynamically pad the inputs received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(100000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation_mismatched\"].shuffle(seed=1150).select(range(1000))\n",
    "small_test_dataset = tokenized_datasets[\"test_mismatched\"].shuffle(seed=1150).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(\n",
    "    small_test_dataset, batch_size=32, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    small_eval_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32]), torch.Size([32, 78]), torch.Size([32, 78]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    \n",
    "batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model and losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Teacher Model & Student Model\n",
    "\n",
    "####  Architecture \n",
    "In the present work, the student - DistilBERT - has the same general architecture as BERT. \n",
    "- The `token-type embeddings` and the `pooler` are removed while `the number of layers` is reduced by a factor of 2. \n",
    "- Most of the operations used in the Transformer architecture `linear layer` and `layer normalisation` are highly optimized in modern linear algebra frameworks.\n",
    "- our investigations showed that variations on the last dimension of the tensor (hidden size dimension) have a smaller impact on computation efficiency (for a fixed parameters budget) than variations on other factors like the number of layers. \n",
    "- Thus we focus on reducing the number of layers.\n",
    "\n",
    "#### Initialize Student Model\n",
    "- To initialize a new model from an existing one, we need to access the weights of the old model (the teacher). \n",
    "- In order to get the weights, we first have to know how to access them. We’ll use BERT as our teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"entailment\",\n",
       "    \"1\": \"neutral\",\n",
       "    \"2\": \"contradiction\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"contradiction\": 2,\n",
       "    \"entailment\": 0,\n",
       "    \"neutral\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "- The student model has the same configuration, except the number of layers is reduced by a factor of 2\n",
    "- The student layers are initilized by copying one out of two layers of the teacher, starting with layer 0.\n",
    "- The head of the teacher is also copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig\n",
    "# Get teacher configuration as a dictionnary\n",
    "configuration = teacher_model.config.to_dict()\n",
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half the number of hidden layer\n",
    "configuration['num_hidden_layers'] //= 2\n",
    "# Convert the dictionnary to the student configuration\n",
    "configuration = BertConfig.from_dict(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create uninitialized student model\n",
    "model = type(teacher_model)(configuration)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursively copies the weights of the (teacher) to the (student).\n",
    "- This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "- The only part that's not fully copied is the encoder, of which only half is copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n",
    "from torch.nn import Module\n",
    "\n",
    "def distill_bert_weights(\n",
    "    teacher : Module,\n",
    "    student : Module,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively copies the weights of the (teacher) to the (student).\n",
    "    This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "    The only part that's not fully copied is the encoder, of which only half is copied.\n",
    "    \"\"\"\n",
    "    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n",
    "    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n",
    "        for teacher_part, student_part in zip(teacher.children(), student.children()):\n",
    "            distill_bert_weights(teacher_part, student_part)\n",
    "    # Else if the part is an encoder, copy one out of every layer\n",
    "    elif isinstance(teacher, BertEncoder):\n",
    "        teacher_encoding_layers = [layer for layer in next(teacher.children())] #12 layers\n",
    "        student_encoding_layers = [layer for layer in next(student.children())] #6 layers\n",
    "        for i in range(len(student_encoding_layers)):\n",
    "            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[2*i].state_dict())\n",
    "    # Else the part is a head or something else, copy the state_dict\n",
    "    else:\n",
    "        student.load_state_dict(teacher.state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = distill_bert_weights(teacher=teacher_model, student=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher parameters : 109484547\n",
      "Student parameters : 66957315\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Teacher parameters :', count_parameters(teacher_model))\n",
    "print('Student parameters :', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.15686353435797"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)/count_parameters(teacher_model) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has 40% less parameters than bert-base-uncased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax\n",
    "\n",
    "$$\n",
    "P_i(\\mathbf{z}_i, T) = \\frac{\\exp(\\mathbf{z}_i / T)}{\\sum_{q=0}^k \\exp(\\mathbf{z}_q / T)}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Distillation\n",
    "\n",
    "#### CE Loss\n",
    "$$\\mathcal{L}_\\text{CE} = -\\sum^N_{j=0}\\sum_{i=0}^k {y}_i^{(j)}\\log(P_i({v}_i^{(j)}, 1))$$\n",
    "\n",
    "#### KL Loss\n",
    "$$\\mathcal{L}_\\text{KD} = -\\sum^N_{j=0}\\sum_{i=0}^k P_i({z}_i^{(j)}, T) \\log (P_i({v}_i^{(j)}, T))$$\n",
    "\n",
    "#### Cosine Embedding Loss\n",
    "$$\\mathcal{L}_{\\text{cosine}}(x_1, x_2, y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(1 - y_i \\cdot \\cos(\\theta_i)\\right)$$\n",
    "\n",
    "<!-- $$\\mathcal{L} = \\lambda \\mathcal{L}_\\text{KD} + (1-\\lambda)\\mathcal{L}_\\text{CE}$$\n",
    " -->\n",
    "\n",
    "#### Total Loss\n",
    "$$\\mathcal{L} = \\mathcal{L}_\\text{KD} + \\mathcal{L}_\\text{CE} + \\mathcal{L}_{\\text{cosine}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillKL(nn.Module):\n",
    "    \"\"\"\n",
    "    Distilling the Knowledge in a Neural Network\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistillKL, self).__init__()\n",
    "\n",
    "    def forward(self, output_student, output_teacher, temperature=1):\n",
    "        '''\n",
    "        Note: the output_student and output_teacher are logits \n",
    "        '''\n",
    "        T = temperature #.cuda()\n",
    "        \n",
    "        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(output_student/T, dim=-1),\n",
    "            F.softmax(output_teacher/T, dim=-1)\n",
    "        ) * T * T\n",
    "        \n",
    "        return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_div = DistillKL()\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 5\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "# Get the metric function\n",
    "if task_name is not None:\n",
    "    metric = evaluate.load(\"glue\", task_name)\n",
    "else:\n",
    "    metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2328320913a141ca8a75f7b1b15e30ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.3264:\n",
      "  - Loss_cls: 0.8480\n",
      "  - Loss_div: 0.0879\n",
      "  - Loss_cos: 0.0433\n",
      "Epoch at 1: Test Acc 0.7620\n",
      "Epoch at 2: Train loss 0.2911:\n",
      "  - Loss_cls: 0.6951\n",
      "  - Loss_div: 0.1367\n",
      "  - Loss_cos: 0.0415\n",
      "Epoch at 2: Test Acc 0.7570\n",
      "Epoch at 3: Train loss 0.2670:\n",
      "  - Loss_cls: 0.5894\n",
      "  - Loss_div: 0.1707\n",
      "  - Loss_cos: 0.0410\n",
      "Epoch at 3: Test Acc 0.7560\n",
      "Epoch at 4: Train loss 0.2523:\n",
      "  - Loss_cls: 0.5248\n",
      "  - Loss_div: 0.1914\n",
      "  - Loss_cos: 0.0406\n",
      "Epoch at 4: Test Acc 0.7710\n",
      "Epoch at 5: Train loss 0.2442:\n",
      "  - Loss_cls: 0.4896\n",
      "  - Loss_div: 0.2027\n",
      "  - Loss_cos: 0.0403\n",
      "Epoch at 5: Test Acc 0.7700\n",
      "Avg Metric 0.7632000000000001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "# Lists to store losses for each epoch\n",
    "train_losses = []\n",
    "train_losses_cls = []\n",
    "train_losses_div = []\n",
    "train_losses_cos = []\n",
    "eval_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    train_loss = 0\n",
    "    train_loss_cls = 0\n",
    "    train_loss_div = 0\n",
    "    train_loss_cos = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # compute student output\n",
    "        outputs = model(**batch) \n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            output_teacher = teacher_model(**batch)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs.logits.size() == output_teacher.logits.size()\n",
    "        \n",
    "        # cls loss \n",
    "        loss_cls  = outputs.loss\n",
    "        train_loss_cls += loss_cls.item()\n",
    "        # distillation loss\n",
    "        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n",
    "        train_loss_div += loss_div.item()\n",
    "        # cosine loss\n",
    "        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n",
    "        train_loss_cos += loss_cos.item()\n",
    "        \n",
    "        # Average the loss and return it\n",
    "        loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n",
    "    train_losses_div.append(train_loss_div / len(train_dataloader))\n",
    "    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "        loss_cls = outputs.loss\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        eval_loss += loss_cls.item()\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n",
    "    \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_list, train_losses, label='Total Train Loss')\n",
    "plt.plot(epochs_list, train_losses_cls, label='Train Loss_cls')\n",
    "plt.plot(epochs_list, train_losses_div, label='Train Loss_div')\n",
    "plt.plot(epochs_list, train_losses_cos, label='Train Loss_cos')\n",
    "plt.plot(epochs_list, eval_losses, label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix (Teacher Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2904e22cbbd43a4a7bc9acabe952318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.6104:\n",
      "Epoch at 1: Test Acc 0.7920\n",
      "Epoch at 2: Train loss 0.3882:\n",
      "Epoch at 2: Test Acc 0.8060\n",
      "Epoch at 3: Train loss 0.2403:\n",
      "Epoch at 3: Test Acc 0.7910\n",
      "Epoch at 4: Train loss 0.1592:\n",
      "Epoch at 4: Test Acc 0.7990\n",
      "Epoch at 5: Train loss 0.1195:\n",
      "Epoch at 5: Test Acc 0.7770\n",
      "Avg Metric 0.793\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(), lr=lr)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    teacher_model.train()\n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_teacher = teacher_model(**batch)\n",
    "        # cls loss \n",
    "        loss = output_teacher.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    \n",
    "    teacher_model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
